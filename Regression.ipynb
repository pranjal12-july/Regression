{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "➤ It models the relationship between two variables using a straight line: one independent (X) and one dependent (Y).\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "➤ Linearity, Independence, Homoscedasticity (constant variance), Normal distribution of residuals.\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "➤ m is the slope — it shows how much Y changes for a one-unit change in X.\n",
        "\n",
        "4. What does the intercept c represent in the equation Y = mX + c?\n",
        "➤ c is the value of Y when X = 0; it’s the point where the line crosses the Y-axis.\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "➤\n",
        "𝑚\n",
        "=\n",
        "𝑛\n",
        "(\n",
        "∑\n",
        "𝑋\n",
        "𝑌\n",
        ")\n",
        "−\n",
        "(\n",
        "∑\n",
        "𝑋\n",
        ")\n",
        "(\n",
        "∑\n",
        "𝑌\n",
        ")\n",
        "𝑛\n",
        "(\n",
        "∑\n",
        "𝑋\n",
        "2\n",
        ")\n",
        "−\n",
        "(\n",
        "∑\n",
        "𝑋\n",
        ")\n",
        "2\n",
        "m=\n",
        "n(∑X\n",
        "2\n",
        " )−(∑X)\n",
        "2\n",
        "\n",
        "n(∑XY)−(∑X)(∑Y)\n",
        "​\n",
        "\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "➤ To minimize the sum of squared differences between observed and predicted Y values.\n",
        "\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "➤ R² indicates how well the model explains the variance in Y. Ranges from 0 to 1.\n",
        "\n",
        "8. What is Multiple Linear Regression?\n",
        "➤ A model that predicts Y using two or more independent variables (X₁, X₂, ... Xₙ).\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "➤ Simple uses one independent variable; multiple uses more than one.\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "➤ Same as Simple, plus no multicollinearity among independent variables.\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "➤ Unequal variance of residuals. It can lead to inefficient estimates and invalid significance tests.\n",
        "\n",
        "12. can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "➤ Remove or combine correlated variables, use PCA, or apply regularization (Ridge/Lasso).\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "➤ One-hot encoding, label encoding, or using dummy variables.\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "➤ To capture combined effects of two or more variables on the dependent variable.\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "➤ In simple regression, it's the Y value when X = 0. In multiple regression, it’s when all Xs are 0, which may not be practical.\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "➤ The slope shows the effect of a one-unit increase in X on Y — it directly influences the prediction.\n",
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "➤ It sets the baseline value of Y when all independent variables are zero.\n",
        "\n",
        "18. What are the limitations of using R² as a sole measure of model performance?\n",
        "➤ It doesn’t penalize complexity and can be misleading for overfitted models.\n",
        "\n",
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "➤ Indicates high variability or uncertainty in the estimate — the coefficient may not be significant.\n",
        "\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "➤ Residuals spread unevenly around the line. It affects model accuracy and inference.\n",
        "\n",
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "➤ It suggests that added variables don’t contribute much and may be overfitting.\n",
        "\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "➤ To avoid bias in coefficients, especially when regularization is used.\n",
        "\n",
        "23. What is polynomial regression?\n",
        "➤ It models the relationship between X and Y as an nth-degree polynomial.\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "➤ Polynomial captures non-linear relationships; linear assumes straight-line relationship.\n",
        "\n",
        "25. When is polynomial regression used?\n",
        "➤ When data shows a non-linear pattern that a straight line can’t capture.\n",
        "\n",
        "26. What is the general equation for polynomial regression?\n",
        "➤\n",
        "𝑌\n",
        "=\n",
        "𝑏\n",
        "0\n",
        "+\n",
        "𝑏\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝑏\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        ".\n",
        ".\n",
        ".\n",
        "+\n",
        "𝑏\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "Y=b\n",
        "0\n",
        "​\n",
        " +b\n",
        "1\n",
        "​\n",
        " X+b\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        " +...+b\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "\n",
        "\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        "➤ Yes, it becomes a multivariate polynomial regression.\n",
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        "➤ Overfitting, complex interpretation, sensitive to outliers.\n",
        "\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "➤ Cross-validation, adjusted R², AIC/BIC, residual analysis.\n",
        "\n",
        "30. Why is visualization important in polynomial regression?\n",
        "➤ Helps detect overfitting/underfitting and understand model behavior.\n",
        "\n",
        "31. How is polynomial regression implemented in Python?\n",
        "➤ Using PolynomialFeatures from sklearn.preprocessing and fitting it with LinearRegression."
      ],
      "metadata": {
        "id": "Q1CTid7J2NUy"
      }
    }
  ]
}